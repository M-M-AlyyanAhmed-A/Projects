{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHHBNEGK0M3G",
        "outputId": "6dd153f5-b8b1-412c-ed0a-6b32613607ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCFOG6-g0M3K",
        "outputId": "d2edf13f-06d4-468a-f8ad-f2c7b6ade80c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in f:\\anaconda3\\lib\\site-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.17.0 in f:\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.4)\n",
            "^C\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e-1BO0RodWBZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d5d21e-8159-4435-c9df-20ae6a582a4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in f:\\anaconda3\\lib\\site-packages (2.16.1)\n",
            "Requirement already satisfied: tensorflow-intel==2.16.1 in f:\\anaconda3\\lib\\site-packages (from tensorflow) (2.16.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (24.3.25)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
            "Requirement already satisfied: setuptools in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (58.0.4)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.12.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.26.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
            "Requirement already satisfied: packaging in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (21.0)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
            "Requirement already satisfied: keras>=3.0.0 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (18.1.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in f:\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in f:\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.37.0)\n",
            "Requirement already satisfied: optree in f:\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
            "Requirement already satisfied: rich in f:\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
            "Requirement already satisfied: namex in f:\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in f:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in f:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in f:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in f:\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2024.2.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in f:\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in f:\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in f:\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in f:\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in f:\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.6.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in f:\\anaconda3\\lib\\site-packages (from packaging->tensorflow-intel==2.16.1->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in f:\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in f:\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in f:\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wC3duzyPdY96"
      },
      "outputs": [],
      "source": [
        "def load_dataset(dataset_directory):\n",
        "    X_train, y_train = [], []\n",
        "    X_test, y_test = [], []\n",
        "\n",
        "    # Define the train and test directories\n",
        "    train_directory = os.path.join(dataset_directory, \"train\")\n",
        "    test_directory = os.path.join(dataset_directory, \"test\")\n",
        "\n",
        "    # Iterate over emotion folders in the training set\n",
        "    for emotion in os.listdir(train_directory):\n",
        "        for filename in os.listdir(os.path.join(train_directory, emotion)):\n",
        "            img_path = os.path.join(train_directory, emotion, filename)\n",
        "            img = cv.imread(img_path, cv.IMREAD_GRAYSCALE)\n",
        "            img = cv.resize(img, (48, 48))\n",
        "            X_train.append(img)\n",
        "            y_train.append(emotion)\n",
        "\n",
        "    # Iterate over emotion folders in the test set\n",
        "    for emotion in os.listdir(test_directory):\n",
        "        for filename in os.listdir(os.path.join(test_directory, emotion)):\n",
        "            img_path = os.path.join(test_directory, emotion, filename)\n",
        "            img = cv.imread(img_path, cv.IMREAD_GRAYSCALE)\n",
        "            img = cv.resize(img, (48, 48))\n",
        "            X_test.append(img)\n",
        "            y_test.append(emotion)\n",
        "\n",
        "    return (np.array(X_train), np.array(y_train)), (np.array(X_test), np.array(y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "u0Px6ahAdbaH"
      },
      "outputs": [],
      "source": [
        "dataset_directory = r'F:\\Projects\\Real Time Emotion Detection\\archive'\n",
        "\n",
        "# Load the dataset\n",
        "(X_train, y_train), (X_test, y_test) = load_dataset(dataset_directory)\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1).astype('float32') / 255\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1).astype('float32') / 255\n",
        "\n",
        "# Define a dictionary to map emotion labels to integer labels\n",
        "emotion_mapping = {\"anger\": 0, \"disgust\": 1, \"fear\": 2, \"happy\": 3, \"sad\": 4, \"surprise\": 5, \"neutral\": 6}\n",
        "\n",
        "# Convert emotion labels to integer labels using the mapping\n",
        "y_train = np.array([emotion_mapping.get(label, 6) for label in y_train])  # Assign 6 as default label if not found\n",
        "y_test = np.array([emotion_mapping.get(label, 6) for label in y_test])    # Assign 6 as default label if not found\n",
        "\n",
        "# Convert integer labels to categorical format\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=7)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "itvfAUVrde1E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01a43fe5-57f5-43e3-ea5f-d79176a7bae1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "F:\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 31ms/step - accuracy: 0.3308 - loss: 1.5746 - val_accuracy: 0.4765 - val_loss: 1.3046\n",
            "Epoch 2/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 31ms/step - accuracy: 0.4984 - loss: 1.2660 - val_accuracy: 0.5304 - val_loss: 1.1768\n",
            "Epoch 3/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 31ms/step - accuracy: 0.5479 - loss: 1.1397 - val_accuracy: 0.5508 - val_loss: 1.1262\n",
            "Epoch 4/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 32ms/step - accuracy: 0.5755 - loss: 1.0648 - val_accuracy: 0.5652 - val_loss: 1.1002\n",
            "Epoch 5/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 32ms/step - accuracy: 0.6080 - loss: 0.9989 - val_accuracy: 0.5716 - val_loss: 1.1132\n",
            "Epoch 6/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 32ms/step - accuracy: 0.6426 - loss: 0.9267 - val_accuracy: 0.5841 - val_loss: 1.0584\n",
            "Epoch 7/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 31ms/step - accuracy: 0.6636 - loss: 0.8709 - val_accuracy: 0.5854 - val_loss: 1.0747\n",
            "Epoch 8/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 32ms/step - accuracy: 0.6931 - loss: 0.8041 - val_accuracy: 0.5858 - val_loss: 1.1008\n",
            "Epoch 9/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 32ms/step - accuracy: 0.7209 - loss: 0.7359 - val_accuracy: 0.5901 - val_loss: 1.1219\n",
            "Epoch 10/10\n",
            "\u001b[1m898/898\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 32ms/step - accuracy: 0.7355 - loss: 0.6907 - val_accuracy: 0.5848 - val_loss: 1.1691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "(X_train, y_train), (X_test, y_test) = load_dataset(dataset_directory)\n",
        "\n",
        "# Preprocess the data\n",
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1).astype('float32') / 255\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1).astype('float32') / 255\n",
        "\n",
        "# Define a dictionary to map emotion labels to integer labels\n",
        "emotion_mapping = {\"anger\": 0, \"disgust\": 1, \"fear\": 2, \"happy\": 3, \"sad\": 4, \"surprise\": 5, \"neutral\": 6}\n",
        "\n",
        "# Convert emotion labels to integer labels using the mapping\n",
        "y_train = np.array([emotion_mapping.get(label, 6) for label in y_train])  # Assign 6 as default label if not found\n",
        "y_test = np.array([emotion_mapping.get(label, 6) for label in y_test])    # Assign 6 as default label if not found\n",
        "\n",
        "# Convert integer labels to categorical format\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=7)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, num_classes=7)\n",
        "\n",
        "# Define model architecture\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(7, activation='softmax')  # 7 classes for 7 emotions\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n",
        "\n",
        "# Save the model\n",
        "model.save('emotion_detection_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0DnL8VxEdI4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d81b9c5-6aab-4369-b1c7-393c2fdddd44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
          ]
        }
      ],
      "source": [
        "# Load the model\n",
        "loaded_model = tf.keras.models.load_model('emotion_detection_model.h5')\n",
        "\n",
        "# Function to detect emotions from webcam feed\n",
        "def detect_emotions():\n",
        "    # Start capturing video from webcam\n",
        "    cap = cv.VideoCapture(0)\n",
        "\n",
        "    # Load Haar cascade for face detection\n",
        "    faceCascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    while True:\n",
        "        # Read a frame from the webcam\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Convert the frame to grayscale for face detection\n",
        "        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Detect faces in the grayscale frame\n",
        "        faces = faceCascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            # Extract the region of interest (ROI) containing the face\n",
        "            roi_gray = gray[y:y + h, x:x + w]\n",
        "            roi_color = frame[y:y + h, x:x + w]\n",
        "\n",
        "            # Resize the ROI to match the input size of the model\n",
        "            resized_roi = cv.resize(roi_gray, (48, 48))\n",
        "            resized_roi = np.expand_dims(resized_roi, axis=-1)\n",
        "            resized_roi = np.expand_dims(resized_roi, axis=0)\n",
        "\n",
        "            # Predict the emotion using the model\n",
        "            prediction = np.argmax(loaded_model.predict(resized_roi))\n",
        "            emotion_label = [\"anger\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"][prediction]\n",
        "\n",
        "            # Display the emotion label on the frame\n",
        "            cv.putText(frame, emotion_label, (x, y - 10), cv.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "\n",
        "            # Draw a rectangle around the face\n",
        "            cv.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "\n",
        "        # Display the frame with emotion detection\n",
        "        cv.imshow('Emotion Detection', frame)\n",
        "\n",
        "        # Break the loop if 'q' is pressed\n",
        "        if cv.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    # Release the video capture object and close all windows\n",
        "    cap.release()\n",
        "    cv.destroyAllWindows()\n",
        "\n",
        "# Call the function to detect emotions from webcam feed\n",
        "detect_emotions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7N_iu3A0M3N"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2JUK36D0M3N"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}