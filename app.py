# -*- coding: utf-8 -*-
"""project (2) .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ILvtdPvQ5rKlOtzOv_JU45zcK6SHBwHK
"""

pip install opencv-python

pip install tensorflow

import os
import cv2 as cv
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers

def load_dataset(dataset_directory):
    X_train, y_train = [], []
    X_test, y_test = [], []

    # Define the train and test directories
    train_directory = os.path.join(dataset_directory, "train")
    test_directory = os.path.join(dataset_directory, "test")

    # Iterate over emotion folders in the training set
    for emotion in os.listdir(train_directory):
        for filename in os.listdir(os.path.join(train_directory, emotion)):
            img_path = os.path.join(train_directory, emotion, filename)
            img = cv.imread(img_path, cv.IMREAD_GRAYSCALE)
            img = cv.resize(img, (48, 48))
            X_train.append(img)
            y_train.append(emotion)

    # Iterate over emotion folders in the test set
    for emotion in os.listdir(test_directory):
        for filename in os.listdir(os.path.join(test_directory, emotion)):
            img_path = os.path.join(test_directory, emotion, filename)
            img = cv.imread(img_path, cv.IMREAD_GRAYSCALE)
            img = cv.resize(img, (48, 48))
            X_test.append(img)
            y_test.append(emotion)

    return (np.array(X_train), np.array(y_train)), (np.array(X_test), np.array(y_test))

dataset_directory = r'F:\Projects\Real Time Emotion Detection\archive'

# Load the dataset
(X_train, y_train), (X_test, y_test) = load_dataset(dataset_directory)

# Preprocess the data
X_train = X_train.reshape(X_train.shape[0], 48, 48, 1).astype('float32') / 255
X_test = X_test.reshape(X_test.shape[0], 48, 48, 1).astype('float32') / 255

# Define a dictionary to map emotion labels to integer labels
emotion_mapping = {"anger": 0, "disgust": 1, "fear": 2, "happy": 3, "sad": 4, "surprise": 5, "neutral": 6}

# Convert emotion labels to integer labels using the mapping
y_train = np.array([emotion_mapping.get(label, 6) for label in y_train])  # Assign 6 as default label if not found
y_test = np.array([emotion_mapping.get(label, 6) for label in y_test])    # Assign 6 as default label if not found

# Convert integer labels to categorical format
y_train = tf.keras.utils.to_categorical(y_train, num_classes=7)
y_test = tf.keras.utils.to_categorical(y_test, num_classes=7)

# Load the dataset
(X_train, y_train), (X_test, y_test) = load_dataset(dataset_directory)

# Preprocess the data
X_train = X_train.reshape(X_train.shape[0], 48, 48, 1).astype('float32') / 255
X_test = X_test.reshape(X_test.shape[0], 48, 48, 1).astype('float32') / 255

# Define a dictionary to map emotion labels to integer labels
emotion_mapping = {"anger": 0, "disgust": 1, "fear": 2, "happy": 3, "sad": 4, "surprise": 5, "neutral": 6}

# Convert emotion labels to integer labels using the mapping
y_train = np.array([emotion_mapping.get(label, 6) for label in y_train])  # Assign 6 as default label if not found
y_test = np.array([emotion_mapping.get(label, 6) for label in y_test])    # Assign 6 as default label if not found

# Convert integer labels to categorical format
y_train = tf.keras.utils.to_categorical(y_train, num_classes=7)
y_test = tf.keras.utils.to_categorical(y_test, num_classes=7)

# Define model architecture
model = tf.keras.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(7, activation='softmax')  # 7 classes for 7 emotions
])

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))

# Save the model
model.save('emotion_detection_model.h5')

# Load the model
loaded_model = tf.keras.models.load_model('emotion_detection_model.h5')

# Function to detect emotions from webcam feed
def detect_emotions():
    # Start capturing video from webcam
    cap = cv.VideoCapture(0)

    # Load Haar cascade for face detection
    faceCascade = cv.CascadeClassifier(cv.data.haarcascades + 'haarcascade_frontalface_default.xml')

    while True:
        # Read a frame from the webcam
        ret, frame = cap.read()

        if not ret:
            break

        # Convert the frame to grayscale for face detection
        gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)

        # Detect faces in the grayscale frame
        faces = faceCascade.detectMultiScale(gray, 1.1, 4)

        for (x, y, w, h) in faces:
            # Extract the region of interest (ROI) containing the face
            roi_gray = gray[y:y + h, x:x + w]
            roi_color = frame[y:y + h, x:x + w]

            # Resize the ROI to match the input size of the model
            resized_roi = cv.resize(roi_gray, (48, 48))
            resized_roi = np.expand_dims(resized_roi, axis=-1)
            resized_roi = np.expand_dims(resized_roi, axis=0)

            # Predict the emotion using the model
            prediction = np.argmax(loaded_model.predict(resized_roi))
            emotion_label = ["anger", "disgust", "fear", "happy", "sad", "surprise", "neutral"][prediction]

            # Display the emotion label on the frame
            cv.putText(frame, emotion_label, (x, y - 10), cv.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

            # Draw a rectangle around the face
            cv.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)

        # Display the frame with emotion detection
        cv.imshow('Emotion Detection', frame)

        # Break the loop if 'q' is pressed
        if cv.waitKey(1) & 0xFF == ord('q'):
            break

    # Release the video capture object and close all windows
    cap.release()
    cv.destroyAllWindows()

# Call the function to detect emotions from webcam feed
detect_emotions()



